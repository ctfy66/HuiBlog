---
title: 'Agent 工程的思考'
date: '2025-12-19'
notionId: '2ce651e18f6080e6b123db25a472b436'
lastEdited: '2025-12-19T06:42:00.000Z'
---


目前agent的工作流程可以范式为感知, 思考, 执行.循环,直到任务完成.


# 思考


深化思考层面的理解


有一般的CoT模式, 通过think step by step, 或则few shot示例,让模型先显示的思考,在回答.


还有ToT(思维树). 类似于对模型的输出做dfs. 解决问题时先让他列出可能的方案, 选择某个方案后, 在这个前提下, 再列出可能的方案. 持续选择或回溯. 直到解决问题.需要代码来控制回溯和剪枝流程.


反思机制: 评判模型输出. 提出改进建议.这个比较重要, 能够有效减少大模型幻觉发生.具体的实现机制需要继续思考.


规划-执行机制:先规划再执行.


## 关于思考, 有CoT, ToT, 规划-执行, 反思机制. 这些机制如何共同使用? 怎么编排这些流程?


我们可以将这四种机制分配到三个不同的层级中：

1. **战略层 (Strategy Layer) —— 负责** **`规划 (Planning)`**
    - **角色**：项目经理 (Manager)。
    - **任务**：把用户模糊的需求拆解成有序的步骤（Sub-tasks）。
    - **机制**：Plan-and-Solve。
2. **执行层 (Execution Layer) —— 负责** **`CoT`** **和** **`ToT`**
    - **角色**：高级工程师 (Worker)。
    - **任务**：执行具体的某一步。
    - **机制选择**：
        - **简单步骤**：直接用 **CoT**（一步推理，快）。
        - **困难步骤**：动态切换到 **ToT**（多方案搜索，慢但稳）。
3. **质检层 (Evaluation Layer) —— 负责** **`反思 (Reflection)`**
    - **角色**：测试/审核人员 (QA/Critic)。
    - **任务**：检查执行层的产出是否合格。如果不合格，打回重做。
    - **机制**：Reflexion loop。

# 感知


再讨论感知层. 这里我的理解是上下文工程为主,具体目标是提供足够的信息, 让模型减少幻觉提高准确率. 并且信息噪声小, 不会转移注意力. 具体的实现有历史对话压缩, RAG知识库检索. 


目前感知的方式:


被动感知: 根据用户问题,自动检索RAG,获取top-n条记忆.注入上下文.


主动感知:有LLM自行推理决断, 调用合适的tool获取需要的信息.


目前Agent的记忆主要分为长期记忆以及短期记忆.


短期记忆是历史对话信息.


长期记忆通常是数据库持久化的信息.


感知层较为重要且复杂,值得单开一篇文章. 


# 执行


目前主流的执行方式有:Tool Use, code interpreter, computer use.


Tool use 是有LLM调用预先定义好的tool. 有执行器执行并将结果返回.


code interpreter: LLM编写代码, 在砂箱中运行代码, 返回结果.适合数据分析, 数学计算等常见.


computer use: 有视觉感知+操作键盘鼠标, 像人一样操作电脑. 目前尚未成熟.


需要关注的点:


安全问题: 可能会执行高危指令, 需要人来监督, 以及代码防范.


回退机制: 如果Agent搞砸了, 能不能回滚版本?

